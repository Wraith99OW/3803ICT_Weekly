{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDbJWoO1yO8e"
      },
      "source": [
        "# Image Classification with CNN - LeNet5 architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzQxqD6HyO8i"
      },
      "source": [
        "In this exercise, we will apply the LeNet5 algorithm to the Fashion MNIST dataset and improve your performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFyVotRvyO8j"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTHLyL1fyO8j",
        "outputId": "534a6453-7d7e-45d5-9ed7-0ae843d4773b",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# TODO: Load the dataset\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# # # If your computer is slow, try to use a subset of data, e.g.\n",
        "# X_train = X_train[:10000]\n",
        "# y_train = y_train[:10000]\n",
        "# X_test = X_test[:2000]\n",
        "# y_test = y_test[:2000]\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8ShXIANyO8l"
      },
      "source": [
        "As you already know, this dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BvNG0PbyO8l"
      },
      "source": [
        "You can have a look at some images if needed, even if you already know them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "lnjqgv-GyO8m",
        "outputId": "78e4cf7f-c872-4716-c5c0-c1cec944b24f",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx], cmap='gray_r')\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdYH6XW1yO8n"
      },
      "source": [
        "Make the data preparation and preprocessing: scale and reshape the data, put the labels to the good shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fjv8XMPByO8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1035ac4d-e1c9-418d-90da-ab00f2cd900f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "X_train_norm = X_train/255\n",
        "X_test_norm = X_test/255\n",
        "\n",
        "\n",
        "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], 28, 28, 1)\n",
        "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], 28, 28, 1)\n",
        "\n",
        "X_train_norm.shape #Should be (60000, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9LKzxR9yO8o"
      },
      "source": [
        "Now build the LeNet5 architecture. You can reuse the one of the course, or try to build it by yourself.\n",
        "\n",
        "The architecture is the following:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1WteTU2FPIVMkBKmMxGpFm5OjsX-szTbB\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GKyMFlL6yO8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dda836a6-abdf-4966-df80-90342202219e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " C1 (Conv2D)                 (None, 26, 26, 6)         60        \n",
            "                                                                 \n",
            " S2 (MaxPooling2D)           (None, 13, 13, 6)         0         \n",
            "                                                                 \n",
            " C3 (Conv2D)                 (None, 11, 11, 16)        880       \n",
            "                                                                 \n",
            " S4 (MaxPooling2D)           (None, 5, 5, 16)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 400)               0         \n",
            "                                                                 \n",
            " C5 (Dense)                  (None, 120)               48120     \n",
            "                                                                 \n",
            " F6 (Dense)                  (None, 84)                10164     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60,074\n",
            "Trainable params: 60,074\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense\n",
        "\n",
        "\n",
        "def lenet5():\n",
        "    \n",
        "    model = Sequential()\n",
        "\n",
        "    # Layer C1\n",
        "    model.add(Conv2D(filters=6, name='C1', kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "    # Layer S2\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S2'))\n",
        "    # Layer C3\n",
        "    model.add(Conv2D(filters=16, name='C3', kernel_size=(3, 3), activation='relu'))\n",
        "    # Layer S4\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S4'))\n",
        "    # Before going into layer C5, we flatten our units\n",
        "    model.add(Flatten())\n",
        "    # Layer C5\n",
        "    model.add(Dense(120, activation='relu', name=\"C5\"))\n",
        "    # Layer F6\n",
        "    model.add(Dense(84, activation='relu', name=\"F6\"))\n",
        "    # Output layer\n",
        "    model.add(Dense(units=10, activation = 'softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "lenet5().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1qBEauqyO8p"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPL3aKnyyO8p",
        "outputId": "82c346bc-1366-4078-ac70-0ef796e462e5",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "30/30 [==============================] - 14s 32ms/step - loss: 1.5509 - accuracy: 0.5156 - val_loss: 0.8339 - val_accuracy: 0.7209\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.7011 - accuracy: 0.7429 - val_loss: 0.6458 - val_accuracy: 0.7595\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.5917 - accuracy: 0.7763 - val_loss: 0.5760 - val_accuracy: 0.7842\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.5391 - accuracy: 0.7987 - val_loss: 0.5383 - val_accuracy: 0.8010\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.5059 - accuracy: 0.8129 - val_loss: 0.5227 - val_accuracy: 0.8071\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.4783 - accuracy: 0.8250 - val_loss: 0.4899 - val_accuracy: 0.8210\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.4604 - accuracy: 0.8336 - val_loss: 0.4905 - val_accuracy: 0.8202\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.4443 - accuracy: 0.8404 - val_loss: 0.4612 - val_accuracy: 0.8333\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.4260 - accuracy: 0.8461 - val_loss: 0.4516 - val_accuracy: 0.8388\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.4098 - accuracy: 0.8533 - val_loss: 0.4310 - val_accuracy: 0.8452\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.4000 - accuracy: 0.8565 - val_loss: 0.4302 - val_accuracy: 0.8471\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3936 - accuracy: 0.8577 - val_loss: 0.4219 - val_accuracy: 0.8482\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3830 - accuracy: 0.8624 - val_loss: 0.4202 - val_accuracy: 0.8475\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.3762 - accuracy: 0.8647 - val_loss: 0.3988 - val_accuracy: 0.8580\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3686 - accuracy: 0.8681 - val_loss: 0.3994 - val_accuracy: 0.8542\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.3662 - accuracy: 0.8676 - val_loss: 0.4033 - val_accuracy: 0.8505\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3596 - accuracy: 0.8704 - val_loss: 0.3887 - val_accuracy: 0.8605\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.3508 - accuracy: 0.8741 - val_loss: 0.3761 - val_accuracy: 0.8643\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.3466 - accuracy: 0.8754 - val_loss: 0.3834 - val_accuracy: 0.8628\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.3433 - accuracy: 0.8767 - val_loss: 0.3810 - val_accuracy: 0.8595\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.3376 - accuracy: 0.8769 - val_loss: 0.3706 - val_accuracy: 0.8657\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.3300 - accuracy: 0.8817 - val_loss: 0.3838 - val_accuracy: 0.8623\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.3262 - accuracy: 0.8824 - val_loss: 0.3732 - val_accuracy: 0.8644\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.3282 - accuracy: 0.8808 - val_loss: 0.3686 - val_accuracy: 0.8643\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.3229 - accuracy: 0.8827 - val_loss: 0.3526 - val_accuracy: 0.8703\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.3140 - accuracy: 0.8863 - val_loss: 0.3557 - val_accuracy: 0.8712\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3166 - accuracy: 0.8859 - val_loss: 0.3491 - val_accuracy: 0.8703\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.3084 - accuracy: 0.8885 - val_loss: 0.3465 - val_accuracy: 0.8730\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.3061 - accuracy: 0.8891 - val_loss: 0.3686 - val_accuracy: 0.8646\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.3043 - accuracy: 0.8884 - val_loss: 0.3491 - val_accuracy: 0.8719\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.3005 - accuracy: 0.8913 - val_loss: 0.3384 - val_accuracy: 0.8767\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.2976 - accuracy: 0.8922 - val_loss: 0.3443 - val_accuracy: 0.8730\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.2934 - accuracy: 0.8936 - val_loss: 0.3355 - val_accuracy: 0.8794\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.2916 - accuracy: 0.8941 - val_loss: 0.3353 - val_accuracy: 0.8770\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.2890 - accuracy: 0.8945 - val_loss: 0.3306 - val_accuracy: 0.8800\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2861 - accuracy: 0.8959 - val_loss: 0.3334 - val_accuracy: 0.8790\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.2848 - accuracy: 0.8959 - val_loss: 0.3299 - val_accuracy: 0.8810\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 1s 26ms/step - loss: 0.2841 - accuracy: 0.8955 - val_loss: 0.3282 - val_accuracy: 0.8802\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.2779 - accuracy: 0.8989 - val_loss: 0.3253 - val_accuracy: 0.8811\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2768 - accuracy: 0.8988 - val_loss: 0.3355 - val_accuracy: 0.8790\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2769 - accuracy: 0.8984 - val_loss: 0.3207 - val_accuracy: 0.8863\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2723 - accuracy: 0.9003 - val_loss: 0.3304 - val_accuracy: 0.8808\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2728 - accuracy: 0.9006 - val_loss: 0.3210 - val_accuracy: 0.8833\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2694 - accuracy: 0.9013 - val_loss: 0.3357 - val_accuracy: 0.8772\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.2687 - accuracy: 0.9015 - val_loss: 0.3190 - val_accuracy: 0.8839\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2660 - accuracy: 0.9020 - val_loss: 0.3162 - val_accuracy: 0.8861\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2650 - accuracy: 0.9036 - val_loss: 0.3169 - val_accuracy: 0.8848\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2648 - accuracy: 0.9032 - val_loss: 0.3155 - val_accuracy: 0.8879\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2585 - accuracy: 0.9058 - val_loss: 0.3168 - val_accuracy: 0.8865\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.2575 - accuracy: 0.9060 - val_loss: 0.3179 - val_accuracy: 0.8843\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.2573 - accuracy: 0.9057 - val_loss: 0.3149 - val_accuracy: 0.8838\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2560 - accuracy: 0.9056 - val_loss: 0.3091 - val_accuracy: 0.8869\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2532 - accuracy: 0.9067 - val_loss: 0.3224 - val_accuracy: 0.8834\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2547 - accuracy: 0.9068 - val_loss: 0.3139 - val_accuracy: 0.8841\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.2495 - accuracy: 0.9087 - val_loss: 0.3100 - val_accuracy: 0.8887\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2477 - accuracy: 0.9094 - val_loss: 0.3098 - val_accuracy: 0.8878\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.2473 - accuracy: 0.9086 - val_loss: 0.3093 - val_accuracy: 0.8858\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2440 - accuracy: 0.9102 - val_loss: 0.3117 - val_accuracy: 0.8886\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2428 - accuracy: 0.9109 - val_loss: 0.3142 - val_accuracy: 0.8873\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2435 - accuracy: 0.9099 - val_loss: 0.3027 - val_accuracy: 0.8931\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2417 - accuracy: 0.9111 - val_loss: 0.3149 - val_accuracy: 0.8856\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2399 - accuracy: 0.9121 - val_loss: 0.3060 - val_accuracy: 0.8903\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2349 - accuracy: 0.9139 - val_loss: 0.3042 - val_accuracy: 0.8906\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2341 - accuracy: 0.9146 - val_loss: 0.3056 - val_accuracy: 0.8910\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2384 - accuracy: 0.9121 - val_loss: 0.3107 - val_accuracy: 0.8908\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2361 - accuracy: 0.9125 - val_loss: 0.3006 - val_accuracy: 0.8922\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2317 - accuracy: 0.9151 - val_loss: 0.3061 - val_accuracy: 0.8920\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.2334 - accuracy: 0.9141 - val_loss: 0.3010 - val_accuracy: 0.8901\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2302 - accuracy: 0.9159 - val_loss: 0.3027 - val_accuracy: 0.8926\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2286 - accuracy: 0.9149 - val_loss: 0.3016 - val_accuracy: 0.8929\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2254 - accuracy: 0.9175 - val_loss: 0.3083 - val_accuracy: 0.8884\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2260 - accuracy: 0.9161 - val_loss: 0.2997 - val_accuracy: 0.8967\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2229 - accuracy: 0.9185 - val_loss: 0.2990 - val_accuracy: 0.8934\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2214 - accuracy: 0.9184 - val_loss: 0.2970 - val_accuracy: 0.8954\n",
            "Epoch 75/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2206 - accuracy: 0.9182 - val_loss: 0.2982 - val_accuracy: 0.8937\n",
            "Epoch 76/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2217 - accuracy: 0.9188 - val_loss: 0.3086 - val_accuracy: 0.8904\n",
            "Epoch 77/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2231 - accuracy: 0.9173 - val_loss: 0.2958 - val_accuracy: 0.8951\n",
            "Epoch 78/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2175 - accuracy: 0.9196 - val_loss: 0.3027 - val_accuracy: 0.8937\n",
            "Epoch 79/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2162 - accuracy: 0.9207 - val_loss: 0.2964 - val_accuracy: 0.8946\n",
            "Epoch 80/100\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2162 - accuracy: 0.9201 - val_loss: 0.2975 - val_accuracy: 0.8960\n",
            "Epoch 81/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.2194 - accuracy: 0.9183 - val_loss: 0.2996 - val_accuracy: 0.8942\n",
            "Epoch 82/100\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.2120 - accuracy: 0.9218 - val_loss: 0.2961 - val_accuracy: 0.8946\n",
            "Epoch 83/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.2135 - accuracy: 0.9204 - val_loss: 0.3114 - val_accuracy: 0.8901\n",
            "Epoch 84/100\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.2109 - accuracy: 0.9214 - val_loss: 0.2935 - val_accuracy: 0.8967\n",
            "Epoch 85/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2077 - accuracy: 0.9225 - val_loss: 0.2930 - val_accuracy: 0.8954\n",
            "Epoch 86/100\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.2073 - accuracy: 0.9238 - val_loss: 0.3002 - val_accuracy: 0.8922\n",
            "Epoch 87/100\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2078 - accuracy: 0.9233 - val_loss: 0.2974 - val_accuracy: 0.8953\n",
            "Epoch 88/100\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.2075 - accuracy: 0.9224 - val_loss: 0.2993 - val_accuracy: 0.8943\n",
            "Epoch 89/100\n",
            "30/30 [==============================] - 0s 17ms/step - loss: 0.2061 - accuracy: 0.9238 - val_loss: 0.3004 - val_accuracy: 0.8952\n",
            "Epoch 90/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2051 - accuracy: 0.9247 - val_loss: 0.2946 - val_accuracy: 0.8943\n",
            "Epoch 91/100\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.2050 - accuracy: 0.9236 - val_loss: 0.2953 - val_accuracy: 0.8972\n",
            "Epoch 92/100\n",
            "30/30 [==============================] - 1s 26ms/step - loss: 0.1991 - accuracy: 0.9258 - val_loss: 0.3019 - val_accuracy: 0.8957\n",
            "Epoch 93/100\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.1997 - accuracy: 0.9262 - val_loss: 0.2980 - val_accuracy: 0.8954\n",
            "Epoch 94/100\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.1995 - accuracy: 0.9263 - val_loss: 0.2954 - val_accuracy: 0.8972\n",
            "Epoch 95/100\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.2012 - accuracy: 0.9251 - val_loss: 0.2967 - val_accuracy: 0.8961\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff64c3b6da0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# TODO: Compile and fit your model\n",
        "import os\n",
        "\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True' #https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "model = lenet5()\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define now our callbacks\n",
        "# callbacks = [EarlyStopping(monitor='val_loss', patience=10), TensorBoard(log_dir='./keras-logs', histogram_freq=0, write_graph=True, write_images=True)]\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
        "\n",
        "# Finally fit the model\n",
        "model.fit(x=X_train_norm, y=y_train_cat, validation_data=(X_test_norm, y_test_cat), epochs=100, batch_size=2048, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf-SqjjOyO8q"
      },
      "source": [
        "Have a look at the tensorboard and see if it gives a deeper understanding of your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2FTj7TSyO8q"
      },
      "source": [
        "Compute then the accuracy of your model. Is it better than a regular MLP used before?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPjJoMQZyO8q",
        "outputId": "b8970d3b-d73a-4618-a296-e574bf488190"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59/59 [==============================] - 1s 4ms/step\n",
            "10/10 [==============================] - 0s 12ms/step\n",
            "accuracy on train with CNN: 0.9280333333333334\n",
            "accuracy on test with CNN: 0.8961\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size = 1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size = batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size = batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with CNN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with CNN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vulsgHiyO8q"
      },
      "source": [
        "We will now add image augmentation to improve our results, especially we will try to reduce overfitting this way.\n",
        "\n",
        "To do so, you can use `ImageDataGenerator` from Keras that makes all the work for you (including rescaling), with the following parameter: \n",
        "* `horizontal_flip=True`\n",
        "\n",
        "For more info about how the `ImageDataGenerator` works, you can check out [this article](https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/).\n",
        "\n",
        "Begin by creating an object `ImageDataGenerator` with this parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-19T11:58:37.442182Z",
          "start_time": "2020-08-19T11:58:37.438397Z"
        },
        "id": "pas-fMSIyO8q"
      },
      "outputs": [],
      "source": [
        "# TODO: Instantiate an ImageDataGenerator object\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7nCnu9syO8r"
      },
      "source": [
        "Finally, you can train your model using this generator, with the method `fit_generator` of your model and the method `flow` of your `ImageDataGenerator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt6wXa3IyO8r",
        "outputId": "0e3a9c97-cbbe-4e91-dce6-d35c79b8e587",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-5da9cbf7d7d8>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 4s 53ms/step - loss: 0.4124 - accuracy: 0.8667 - val_loss: 0.3275 - val_accuracy: 0.8794\n",
            "Epoch 2/100\n",
            "58/58 [==============================] - 3s 48ms/step - loss: 0.2782 - accuracy: 0.8984 - val_loss: 0.3028 - val_accuracy: 0.8908\n",
            "Epoch 3/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.2647 - accuracy: 0.9032 - val_loss: 0.2968 - val_accuracy: 0.8927\n",
            "Epoch 4/100\n",
            "58/58 [==============================] - 3s 43ms/step - loss: 0.2592 - accuracy: 0.9046 - val_loss: 0.2958 - val_accuracy: 0.8952\n",
            "Epoch 5/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.2537 - accuracy: 0.9062 - val_loss: 0.2918 - val_accuracy: 0.8957\n",
            "Epoch 6/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.2478 - accuracy: 0.9092 - val_loss: 0.2962 - val_accuracy: 0.8958\n",
            "Epoch 7/100\n",
            "58/58 [==============================] - 3s 55ms/step - loss: 0.2431 - accuracy: 0.9099 - val_loss: 0.2985 - val_accuracy: 0.8974\n",
            "Epoch 8/100\n",
            "58/58 [==============================] - 4s 61ms/step - loss: 0.2421 - accuracy: 0.9104 - val_loss: 0.2986 - val_accuracy: 0.8941\n",
            "Epoch 9/100\n",
            "58/58 [==============================] - 3s 43ms/step - loss: 0.2371 - accuracy: 0.9131 - val_loss: 0.2935 - val_accuracy: 0.8962\n",
            "Epoch 10/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.2339 - accuracy: 0.9139 - val_loss: 0.2983 - val_accuracy: 0.8936\n",
            "Epoch 11/100\n",
            "58/58 [==============================] - 3s 43ms/step - loss: 0.2360 - accuracy: 0.9117 - val_loss: 0.2911 - val_accuracy: 0.8954\n",
            "Epoch 12/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.2316 - accuracy: 0.9136 - val_loss: 0.2962 - val_accuracy: 0.8957\n",
            "Epoch 13/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.2337 - accuracy: 0.9138 - val_loss: 0.2933 - val_accuracy: 0.8952\n",
            "Epoch 14/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.2266 - accuracy: 0.9170 - val_loss: 0.2902 - val_accuracy: 0.8967\n",
            "Epoch 15/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.2243 - accuracy: 0.9175 - val_loss: 0.2905 - val_accuracy: 0.8983\n",
            "Epoch 16/100\n",
            "58/58 [==============================] - 4s 63ms/step - loss: 0.2209 - accuracy: 0.9180 - val_loss: 0.3083 - val_accuracy: 0.8924\n",
            "Epoch 17/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.2228 - accuracy: 0.9172 - val_loss: 0.2881 - val_accuracy: 0.8973\n",
            "Epoch 18/100\n",
            "58/58 [==============================] - 3s 43ms/step - loss: 0.2166 - accuracy: 0.9194 - val_loss: 0.2899 - val_accuracy: 0.8966\n",
            "Epoch 19/100\n",
            "58/58 [==============================] - 3s 44ms/step - loss: 0.2190 - accuracy: 0.9182 - val_loss: 0.2905 - val_accuracy: 0.8987\n",
            "Epoch 20/100\n",
            "58/58 [==============================] - 4s 65ms/step - loss: 0.2174 - accuracy: 0.9194 - val_loss: 0.2830 - val_accuracy: 0.9016\n",
            "Epoch 21/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.2124 - accuracy: 0.9215 - val_loss: 0.2926 - val_accuracy: 0.8986\n",
            "Epoch 22/100\n",
            "58/58 [==============================] - 3s 43ms/step - loss: 0.2132 - accuracy: 0.9195 - val_loss: 0.2975 - val_accuracy: 0.8987\n",
            "Epoch 23/100\n",
            "58/58 [==============================] - 3s 44ms/step - loss: 0.2153 - accuracy: 0.9197 - val_loss: 0.2927 - val_accuracy: 0.8982\n",
            "Epoch 24/100\n",
            "58/58 [==============================] - 6s 103ms/step - loss: 0.2091 - accuracy: 0.9219 - val_loss: 0.2907 - val_accuracy: 0.8977\n",
            "Epoch 25/100\n",
            "58/58 [==============================] - 3s 44ms/step - loss: 0.2121 - accuracy: 0.9211 - val_loss: 0.2858 - val_accuracy: 0.9027\n",
            "Epoch 26/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.2083 - accuracy: 0.9225 - val_loss: 0.2874 - val_accuracy: 0.8999\n",
            "Epoch 27/100\n",
            "58/58 [==============================] - 7s 112ms/step - loss: 0.2115 - accuracy: 0.9209 - val_loss: 0.2862 - val_accuracy: 0.9026\n",
            "Epoch 28/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.2049 - accuracy: 0.9245 - val_loss: 0.2913 - val_accuracy: 0.8991\n",
            "Epoch 29/100\n",
            "58/58 [==============================] - 3s 49ms/step - loss: 0.2053 - accuracy: 0.9236 - val_loss: 0.3015 - val_accuracy: 0.8967\n",
            "Epoch 30/100\n",
            "58/58 [==============================] - 2s 42ms/step - loss: 0.2019 - accuracy: 0.9248 - val_loss: 0.2890 - val_accuracy: 0.9001\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff5b7a6a980>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# TODO: train your model\n",
        "batch_size = 1024\n",
        "model.fit_generator(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n",
        "                    validation_data=(X_test_norm, y_test_cat), callbacks=callbacks,\n",
        "                    steps_per_epoch=len(X_train_norm) / batch_size, epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuzFke8pyO8r"
      },
      "source": [
        "Recompute the accuracy of your model, does it improve your performances with data augmentation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsTm86tuyO8r",
        "outputId": "284b8925-89e6-4aed-c684-31b4c9de93e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59/59 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "accuracy on train with NN: 0.9331166666666667\n",
            "accuracy on test with NN: 0.9001\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size=1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size = batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size = batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with NN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with NN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOzkdGf7yO8s"
      },
      "source": [
        "You can now try to improve even more your results. For example, add more parameters to your `ImageDataGenerator`, play with some hyperparameters, and so on..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}